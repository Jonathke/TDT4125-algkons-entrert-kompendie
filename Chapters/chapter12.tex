\section{Onlinealgoritmer}
I denne seksjonen ser vi på noe ganske annet enn resten av pensum. For å sammenligne med approksimasjoner som vi har hatt mye fokus på, hadde vi da typisk et optimeringsproblem som kun kunne løses eksakt i eksponensiell tid (med mindre $P=NP$), så vi ønsket å oppnå en approksimasjonsrate, som sa noe om hvor bra løsningen vår (som kunne oppnås i polynomisk tid) var i forhold til den eksakte løsningen. Som vi skal se er definisjonene i et online-problem basert på samme strategi, men med en litt annen problemstilling.

\subsection{Onlineproblem og Kompetitiv Analyse}

Et onlineproblem er er en et problem der problem kommer som en sekvens av forespørsler $I = (x_1, x_2,...,x_n)$. En onlinealgoritme er da en algoritme som outputter et svar $O = (y_1, y_2,...,y_n)$, men der svar $y_i$ kun er avhengig av $x_1,...,x_i,y_1,...,y_{i-1}$. Onlineproblemer kan på lik linje med det vi har sett tidligere være minimerings eller maksimeringsproblemer. For å få en tilsvarende metrikk til approksimasjonsrate for å si noe om hvor "bra" onlinealgoritmen er, ser vi på det som kalles \emph{competitive ratio}. En onlinealgoritme er $c$-competitive dersom:

\begin{itemize}
    \item $cost(ALG(I)) \leq c(cost(OPT(I))) + \alpha$, for et minimeringsproblem
    \item $gain(OPT(I)) \leq c(gain(ALG(I))) + \alpha$, for et maksimeringsproblem
\end{itemize}

for en konstant $\alpha$, og der $OPT(I)$ betegner den optimale løsningen som kunne vært oppnådd dersom man viste hele $I = (x_1,...,x_n)$ på forhånd. Vi sier at $ALG$ er strictly $c$-competitive dersom $\alpha = 0$, og strongly $c$-competitive, dersom en $c$-competitive algoritme er det beste som kan oppnås for dette problemet. Videre er $ALG$ not competitive dersom det ikke eksisterer en slik konstant $c$. Dette impliserer typisk at $c$ er avhengig av $n$. For å se at disse definisjonene gir mening, se at dersom $\frac{cost(ALG(I_i))}{cost(OPT(I_i))} \leq c, \forall i \in \mathbb{N}^+$ og $ lim_{i \rightarrow \infty}cost(OPT(I_i)) = \infty$, så kan ikke $ALG$ være $(c-\epsilon)$-competitive, siden impliserer at $cost(ALG(I_i)) \leq (c-\epsilon)cost(OPT(I_i)) + \alpha$ som vil medføre at $\frac{cost(ALG(I_i))}{cost(OPT(I_i))}- \frac{\alpha}{cost(OPT(I_i))} \leq c-\epsilon$ ($\frac{\alpha}{cost(OPT(I_i))}$ går mot $0$). Dette kan også overføres til strongly $c$-competitive, ved å si at den første ulikheten gjelder for alle $ALG$.

\subsection{Paging}
Paging er et klassisk onlineproblem, og faktisk det eneste vi skal se på. Det er motivert at vi må ha en smart måte å cache minne på. Vi ser på en veldig forenklet modell som følger. Hovedminne består av såkalte pages $p_1,...,p_m$, der alle tar like mye plass. I tillegg har vi en cache som har plass til $k$ slike pages. Problemet $I = (x_1,x_2,...,x_n)$ er page requests slik at $x_i \in \{p_1,...,p_m\}$ blir requesta ved tid $T_i$. En onlinealgoritme $ALG$ for dette problemet styrer da strategien for hvilke pages som skal være i cachen ved hvert tidsteg. Cachen (notert som en tuppel $B_t$ for tidsteg $T_t$) er ved $T_0$ satt til $B_0 = (p_1,p_2,...,p_k)$. Dersom $x_i \in B_{i-1}$ (omtalt som page hit), outputter algoritmen $y_i = 0$. Motsatt, dersom $x_i \notin B_{i-1}$ (omtalt som page miss) må $ALG$ velge en $p_j \in B_{i-1}$ som den fjerner før den legger til $x_i$, slik at $B_i = (B_{i-1} \setminus \{p_j\}) \cup \{x_i\}$. Da setter den også $y_i = p_j$. Målet med paging er å minimere $cost(ALG(I)) = |\{i | y_i \neq 0\}|$. Merk at denne definisjonen setter visse restriksjoner for $ALG$. For det første må den initialiseres til de $k$ første pagene, og for det andre får den ikke lov å bytte ut pages utenom når det kommer en $x_i \notin B_{i-1}$ (denne egenskapen gjør at $ALG$ kalles en \emph{demand paging algorithm}). Det kan vises at ingen av disse restriksjonene egentlig er noen restriksjoner for den teoretiske analysen (hvordan algoritmen initialiseres kan fanges opp av $\alpha$ i fra competitive rate definisjonen, mens alle paging algoritmer kan konverteres til en \emph{demand paging algorithm} uten å øke competitive rate).

Vi skal se på en rekke veldig intuitive algoritmer for paging. De er $FIFO$ (First In First Out), $LIFO$ (Last In First Out), $LFU$ (Least Frequently Used), $LRU$ (Least Recently Used), $FWF$ (Flush When Full, merk at denne ikke oppfyller kravet til en \emph{demand paging algorithm}) og $LFD$ (Longest Forward Distance, en offlinealgoritme). Alle disse algoritmene fungerer slik du tror utifra navnet, se evt. boka for mer formelle definisjoner. Målet vil bli å finne hvem av disse som er strongly $c$-competitive.

\subsubsection{Øvre grense}
Et konsept som blir sentralt i competitive-analysen vår er såkalt $k$-fase partisjoneringer. De er definert som følger: For en $I = (x_1,...,x_n)$ kan vi $k$-partisjonere $I$ i etterfølgende faser $P_1, ...,P_N$ slik at fase $P_1$ starter når den første page missen intreffer, og deretter starter etterfølgende faser når den $k+1$ distinkte pagen requestes. Med andre ord inneholder hver fase $k$ distinkte pages (muligens utenom den siste), og videre er de av maksimal lengde.

Med en $k$-fase partisjonering kan vi enkelt analysere f.eks. $FIFO$. Det er ikke vanskelig å se at i løpet av en fase $P_i$ vil $FIFO$ maksimalt få $k$ page misses (siden hver fase inneholder $k$ distinkte pages). Videre må vi analysere hvor bra det er mulig å oppnå (altså $cost(OPT(I))$). I en fase MÅ $OPT$ få minst $1$ page miss (vi antar alltid uten tap av generalitet at $x_1$ er en page miss for begge). Dermed får vi $cost(OPT(I)) \geq N$ og samtidig $cost(FIFO(I)) \leq kN$, og det følger at $FIFO$ er en strictly-$k$-competitve online algoritme for paging. Lignende argumenter gir samme resultat for $LRU$ og $FWF$.
\subsubsection{Nedre grense}
Hvor bra er det generelt mulig å oppnå? Dersom vi ønsker å vise at $FIFO$ (og $LRU$ og $FWF$) er strongly-$k$-kompetitive, må vi klare å bevise at ingen online algoritme kan prestere bedre enn $k$-kompetitive. Heldigvis er dette ikke vanskelig!

For å vise dette introduserer vi en adversary som konstruerer $I$ på værst mulig måte for $ALG$. Vi ser for oss et enkelt tilfelle der $m = k+1$. Idéen er at vår adversary, som vet hvordan $ALG$ fungerer konstruerer $I$ slik at den alltid requester den som $ALG$ nettopp byttet ut (altså $x_i = y_{i-1}$). Vi ser på $|I| \equiv 0 \; (\mathrm{mod}\;{k})$, slik at vi kan nøyaktig partisjonere $I$ i faser på lenge $k$. $ALG$ har da $k$ page misses under en fase, mens en $OPT$ vil naturlig nok ha maksimalt $1$ miss. Dette kan formaliseres som at $OPT$ ved en page miss bytter med en $p_j$ som ikke er del av samme fase (dette er mulig, siden fasene kun er $k$ lange). Det kan naturlig nok eksistere flere slike, det er ikke viktig for analysen, men for ordens skyld bytter da $OPT$ ut med den som er lengst til blir requesta neste gang ($OPT$ implementerer altså strategien $LFD$). Dermed ser vi at det teoretisk beste tilfelle for en online algoritme er å være $k$-competitive, og vi har dermed vist at $FIFO$ (og $LRU$ og $FWF$) er strongly-$k$-competitive.

Denne adversary-analysen gir oss også helt trivielle beviser for at både $LIFO$ og $LFU$ er not competitive. Se evt. boka.


\subsubsection{Markeringsalgoritmer}
Vi ønsker å generaliserer enkelte av de strongly-$k$-competitive paging algoritmene. For å gjøre dette introduseres konsepte Markeringsalgoritmen (for paging). De fungerer slik at når en request $x_i$ kommer, så markeres den i cachen (om den ikke allerede er markert). Dersom $x_i \notin B_{i-1}$ har vi kun lov til å fjerne umarkerte pages. Dersom alle pagene i cachen er markerte, så unmarkes alle sammen, og vi kan velge fritt. Når vi legger inn $x_i$ i $B_i$ markeres den med en gang.

Analysen av markingeringsalgoritmen er veldig enkel. Vi ser for oss en partisjonering, der hver fase starter hver gang vi unmarker hele cahcen. Det er ikke vanskelig å se at en slik partisjonering tilsvarer $k$-partisjoneringen, lik den omtalt i tidligere avsnitt (se detaljer i boka). Videre er det helt åpenbart at markeringsalgoritmen ikke kan ha mer enn $k$ page misses i en fase. Dermed er også markeringsalgoritmen strongly-$k$-kompetitive.

For å vise at en algoritme er en markeringsalgoritme holder det å bevise at algoritmen aldri fjærner en page som er markert. Med rask tenking ser vi da f.eks at $LRU$ og $FWF$ er markeringsalgoritmer, mens f.eks $FIFO$ er ikke det.
