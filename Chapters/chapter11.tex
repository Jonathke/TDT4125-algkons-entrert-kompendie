\section{Randomisering}
Randomiserte algoritmer er definert som en randomisert Turing maskin, altså en Turing maskin som også tar inn en bitstream av tilfeldige bits, og bruker dette i algoritmen. Resultatet av dette er at algoritmen ikke lenger er deterministisk, men kan produsere forskjellig output, basert på forskjellig input. MVO fra forrige kapittel er et eksempel på en randomisert algoritme. Som vi skal se, kan vi generelt gjøre om randomiserte algoritmer til deterministiske. Men, grunnen til at vi fremdeles er intereserte i randomiserte algoritmer er at de ofte er enklere å analysere. Det ødelegger f.eks. for en adversary som ønsker å lage dårligst mulig input for en algoritme. Et formål som vi skal se er random sampling, som ofte gir en nyttig i approksimering.

To raske definisjoner er gjennomgått på Las Vegas og Monte Carlo algoritmer. Den enkle, men unøyaktige huskereglen er at Las Vegas algoritmer er "alltid korrekte, men ikke alltid raske", mens Monte Carlo algoritmer er "Alltid raske, men ikke alltid korrekte". En litt mer formell definisjon sier at Las Vegas algoritmen alltid terminerer, og da enten outputter et korrekt svar, eller ingen svar. Kjøretiden her er avhengig av tilfeldigheter. Monte Carlo algoritmer derimot terminerer enten uten svar, eller med et svar, men svaret er ikke nødvendigvis riktig. Kjøretiden til en Monte Carlo algoritme er også deterministisk. Vi kan ha en-sidig eller to-sidige Monte Carlo algoritmer som hhv. betyr at den kan ta feil på både ja/nei, eller at en av svarende er garantert riktige (f.eks. om den returnerer nei vet vi at svaret er nei, mens om den returnerer ja kan det fremdeles hende svaret er nei).

\subsection{Max-SAT, Max-Cut og Min Cut}
Dette er to enkle problemer, som begge har en helt triviell randomisert algoritme, men som gir oss en helt ok approksimering. Merk at når vi snakker om randomisert approksimering, så er det snakk om en nedre grense for hvor nære \emph{forventningsverdien} er en optimal løsning. I Max-SAT problemet har vi variabler $x_1,...,x_n$, og vekter $w_1,...,w_m$ tilhørende bolske funksjoner $C_1,...C_m$, formulert som $C_j = x_k \vee x_{k+1} \vee ... \vee x_{k + l}$, der $k+i \in \{1,...,n\}$ (ikke nødvendigvis etterfølgende), og $l$ betegner lengden på klausul $C_j$. Ved å sette hver $x_i$ til $0,1$ med like stor sannsynlighet, får vi en randmoisert $\frac{1}{2}$-approksimasjon. dette, se at vi produserer løsningen $W$, og $y_1$ betegner hvorvidt klausul $C_i$ er true, så får vi $E[W] = \sum\nolimits_{j=1}^{m}w_jE[y_j] = \sum\nolimits_{j=1}^{m}w_jP(C_j true)$. Det er lett å se at på $P(C_jtrue)=1-(\frac{1}{2})^{l_j}$. Siden $l_j \geq 1$ får vi altså $E[W] \geq \frac{1}{2}\sum\nolimits_{j=1}^{m}w_j \geq \frac{1}{2}OPT$. Som en dirkete konsekvens av denne analysen ser vi at om alle klausuler oppfyller $l_j \geq k$ så får vi faktisk en ($1-(\frac{1}{2})^k)$-approksimasjon. 

Det andre problemet er et Max-Cut problem i en hvilken som helst graf (se definisjon av kutt i Flyt kapitlene). Dette gjør vi på nøyaktig samme måte (legger inn en node i løsningen vår med $0.5$ sannsynlighet), og analysen er mer eller mindre og helt lik, så vi får også her en $(\frac{1}{2})$-approksimasjon.

Det motsatte problemet, Min-Cut, har også en tilsvarende enkel approksimasjon, men vi utfører den litt anderledes. Det blir raskt klart hvorfor. I hvert steg trekker vi sammen to noder i grafen (fjerner alle kanter mellom dem, og merger dem), og beholder alle andre kanter. Legg merke til at med mindre kanten er i det optimale min cutet (en node i settet, en node utenfor), så endrer da ikke min-cuttet seg i den nye grafen. Dermed er idéen at vi gjør dette helt til det kun gjenstår to noder. Hvis vi har vært heldig, og ungått å fjærne kanter med en endenode i kuttet, og en utenfor, har vi nå det optimale min-cuttet. La $\delta(S)$ betegne dette kantene i min cuttet, og la $|\delta(S)| = k$. Vi har dermed at alle noder må ha grad $\geq k$, siden ellers hadde den noden vært et min cut. Sannsynligheten for at når vi fjerner en kant, så er den kanten i $\delta(S)$ er altså $\leq \frac{k}{\frac{nk}{2}}=\frac{2}{n}$. Da blir sansyntligheten for at vi algoritmen fjærner en kant ila. sine $n-2$ iterasjoner $\leq 1-\frac{2}{n^2}$ (regnes ut som avhengige sannsynligheter. Nøkkelen er nå at denne algoritmen er mega-rask, så vi kan kjøre den mange ganger for å oppnå en bedre nedre grense for sannsynligheten for at løsningen er riktig. Legg merke til at $(1-\frac{2}{n^2})^\frac{n^2}{2} < \frac{1}{e}$ Dermed har vi for eksempel etter å ha kjørt algoritmen $\frac{n^2}{2}$ ganger mindre enn $\frac{1}{e}$ sannsynlighet for at den beste løsningen ikke er optimal.

\subsection{Derandomisering}
Som nevnt følger et lite eksempel på derandomisering. Målet er å gjøre en randomisert algoritme deterministisk, uten at det går på bekostning av ytelsen. Vi tar Max-SAT som et raskt eksempel, se evt. boka for mer detaljer.

Når vi skal velge $x_1$, så er tanken at vi ser på de to verdiene $E[W | x_1 true]$ og $E[W | x_1 false]$. Det er ikke gitt at denne forventningsverdien generelt er lett å regne ut, men antar vi at den er det, velger vi den høyeste av disse. Antar vi at $true$ gir best resultat, er det er klart at $E[W | x_1 true] \geq E[W]$, siden $E[W] = \frac{1}{2}(E[W | x_1 true] + E[W | x_1 false])$. Dette kan vi så gjøre, og vise med induksjon at holder for alle variablene. I Max-SAT er naturlig nok denne forventningsverdien også enkel og regne ut, så dette er nok for å derandomisere Max-SAT algoritmen vår fra isted.

\subsection{Randomisert Avrunding av Lineærprogrammer}
En veldig intuitiv måte å benytte randomisering for å løse 0-1 IPer (lineærprogram der variabler kun tar verdier $\{0,1\}$), er å løse LP-relakseringen, oppnå løsningen $X^*$, og sette i den faktiske løsningen vår sette $x_i = 1$, med sannsynlighet $x_i^*$. Dette vil generelt føre til at restriksjoner kan bli brutt, men ikke med så mye. Om vi kan finne en sannsynlighet for at ingen restriksjoner blir brutt som er polynomisk i input størrelsen, har vi sett at vi kan kjøre algoritmen et polynomisk antal ganger for å oppnå en grei sannsynlighet for suksess. Har vi denne egenskapen, sier boken at algoritmen fungerer med \emph{high probability}. 

Vi ser på randomisert avrunding for mengdedekke problemet fra tidligere, og utfører taktikken fra forrige avsnitt. Vi ønsker å finne en sannsynlighet for at algoritmen returnerer et ugyldig mengdedekke. Vi ser at sannsynligheten for at element $e_i$ ikke er dekt kan skrives som $P[e_i \text{ ikke dekt}] = \prod\nolimits_{j:e_i \in S_j}(1-x_j^*)$. Som tidligere vet vi at $(1-x) \leq e^{-x}$, så vi får $P[e_i \text{ ikke dekt}] \leq \prod\nolimits_{j:e_i \in S_j}e^{-x_j^*} = e^{(-\sum\nolimits_{j:e_i \in S_j}x_j^*)} \leq e^{-1}$, der den siste ulikheten kommer av at $x^*$ ikke bryter LP restriksjonene. Forventningsverdien til algoritmen vår nå er jo $PRIM$, men tar vi nå sannsynligheten for at det finnes et udekt element, blir den for høy. Men, ved å øke forventningsverdien (husk, dette er et minimeringsproblem) kan vi få en randomisert algoritme som løser mengdedekke med \emph{high probability}. For å gjøre dette, si at vi setter $x_i = 1$ med sannsynlighet $1 - (1-x_i^*)^{cln(n)}$ (intuisjonen her er at $x_i^*$ gir en bias til en mynt som vi flipper $cln(n)$ ganger, der 1 heads er nok til å sette $x_i = 1$). Ved samme analyse for isted ser vi nå at $P[e_i \text{ ikke dekt}] = n^{-c}$, som holder når vi ser på sannsynligheten for at det eksisterer et udekt element. Analyse av forventningsverdien gir nå $E[\sum\nolimits_{j=1}^{m}w_jx_j \leq \sum\nolimits_{j=1}^{m}w_j(cln(n)x_j^* = (cln(n))PRIM \leq (cln(n))OPT$ (for bevis på den første ulikheten se boka), som gir at denne algoritmen er en $\mathcal{O}(ln(n))$-approksimering av mengdedekke problemet. 

For en lignende analyse/strategi på Max-SAT får vi en $(1-\frac{1}{e})$-approksimering. Se boka for detaljer (strategien er den samme, løs LP relakseringen, og bruk løsningen til å avrunde). Men, det kule resultatet her er at denne strategien fungerer best når $l_j$ er lav, mens som vi har sett er den trivielle algoritmen fra starten av dette kapitellet best når $l_j$ er høy. La $W_1$ betegne løsningen til den randomiserte avrundingen, mens $W_2$ betegner den trivielle algoritmen. Ved å nå konstruere en ny algoritme som kjører begge de to og alltid velger $max(W_1,W_2)$ får vi en algoritme med bedre teoretisk randomisert approksimasjon en begge de forrige! En slik algoritme er nemlig en randomisert $(\frac{3}{4})$-approksimasjon. Dette er ikke så vanskelig å se, vi får $E[max(W_1,W_2)] \geq \frac{1}{2}E[W_1] + \frac{1}{2}E[W_2] \geq f(l_j)OPT$, der $f(l_j) = [\frac{1}{2}(1-(1-\frac{1}{l_j})^{l_j})+\frac{1}{2}(1-2^{-l_j})]\geq \frac{3}{4}, \forall l_j \in \mathbb{N}$ (her betegner $l_j$ lengden på den lengste klausulen).
